# Estado del arte {#state-of-art}

## El "naive approach"

tagueo con expresiones regulares...

## Redes neuronales y modelos estadísticos

Redes neuronales convolucionales
https://es.wikipedia.org/wiki/Redes_neuronales_convolucionales

## La formula para "deep-learning"

articulo spacy

### embed
```{r formula-embed, echo = FALSE, fig.pos="H", fig.align = 'center', fig.cap='TODO: embed'}
knitr::include_graphics('assets/deep-learning-formula-nlp_embed.svg')
```
### encode
```{r formula-encode, echo = FALSE, fig.pos="H", fig.align = 'center', fig.cap='TODO: encode'}
knitr::include_graphics('assets/deep-learning-formula-nlp_encode.svg')
```
### attend
```{r formula-attend, echo = FALSE, fig.pos="H", fig.align = 'center', fig.cap='TODO: attend'}
knitr::include_graphics('assets/deep-learning-formula-nlp_attend.svg')
```
### predict
```{r formula-predict, echo = FALSE, fig.pos="H", fig.align = 'center', fig.cap='TODO: predict'}
knitr::include_graphics('assets/deep-learning-formula-nlp_predict.svg')
```

Here is a review of existing methods.


## statistical entity recognition model

## Word vectors
<!-- TODO expo word vectors
Los vectores de palabras son particularmente útiles para términos que no están bien representados en los datos de entrenamiento etiquetados.
Por ejemplo, si está haciendo un reconocimiento de entidad con nombre, siempre habrá muchos nombres de los que no tendrá ejemplos.
Por ejemplo, imagine que sus datos de capacitación contienen algunos ejemplos del término "Microsoft", pero no contienen ningún ejemplo del término "Symantec".
En su muestra de texto sin formato, hay muchos ejemplos de ambos términos, y se usan en contextos similares.
Los vectores de palabras ponen ese hecho a disposición del modelo de reconocimiento de entidad. Todavía no verá ejemplos de "Symantec" etiquetados como empresa. Sin embargo, verá que "Symantec" tiene un vector de palabras que generalmente corresponde a los términos de la compañía, por lo que puede hacer la inferencia.
-->

$$\vec{king} - \vec{man} + \vec{woman} \approx \vec{queen}$$

[@ethayarajh-etal-2019-towards]

```{r vec-parallelogram, echo = FALSE, fig.pos="H", fig.align = 'center', fig.cap='Parallelogram structure in the vector space (by definition)'}
knitr::include_graphics('assets/parallelogram.png')
```


https://www.youtube.com/watch?v=sqDHBH9IjRU
SPACY'S ENTITY RECOGNITION MODEL: incremental parsing with Bloom embeddings & residual CNNs

https://github.com/explosion/talks/blob/master/2017-11-02_Practical-and-Effective-Neural-NER.pdf
https://github.com/explosion/talks/blob/master/2018-04-12_Embed-Encode-Attend-Predict.pdf
